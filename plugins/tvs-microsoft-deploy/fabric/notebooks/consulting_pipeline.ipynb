{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "trident": {
   "lakehouse": {
    "default_lakehouse_name": "lh-consulting-data",
    "default_lakehouse_workspace_id": ""
   }
  },
  "tvs_orchestration": {
   "pipeline_id": "pl_consulting_alignment",
   "schedule": {
    "frequency": "hourly",
    "cron_utc": "30 * * * *"
   },
   "lineage": [
    "sv_sales_fact_conformed"
   ],
   "alert_route": "FABRIC_PIPELINE_TEAMS_WEBHOOK"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulting Data Pipeline\n",
    "\n",
    "Processes consulting data for Lobbi Consulting and Medicare Consulting entities.\n",
    "Reads engagements, activities, and shared prospects to calculate:\n",
    "- Pipeline value by stage and entity\n",
    "- Lead conversion rates\n",
    "- Engagement health scores\n",
    "\n",
    "**Schedule:** Daily at 5:00 AM UTC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, current_timestamp, when, coalesce, count, sum as spark_sum,\n",
    "    avg, datediff, to_date, row_number, round as spark_round,\n",
    "    months_between, current_date\n",
    ")\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from datetime import datetime\n",
    "\n",
    "LAKEHOUSE = \"lh-consulting-data\"\n",
    "BASE_PATH = f\"abfss://{LAKEHOUSE}@onelake.dfs.fabric.microsoft.com\"\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Read all consulting tables\n",
    "df_accounts = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_accounts\")\n",
    "df_contacts = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_contacts\")\n",
    "df_engagements = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_engagements\")\n",
    "df_activities = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_activities\")\n",
    "df_prospects = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_sharedprospects\")\n",
    "df_implementations = spark.read.format(\"delta\").load(f\"{BASE_PATH}/Tables/dv_implementations\")\n",
    "\n",
    "# Entity label mapping\n",
    "ENTITY_LABELS = {\n",
    "    100000000: \"Lobbi Consulting\",\n",
    "    100000001: \"Medicare Consulting\"\n",
    "}\n",
    "\n",
    "# Engagement status labels\n",
    "STATUS_LABELS = {\n",
    "    100000000: \"Proposed\",\n",
    "    100000001: \"Negotiation\",\n",
    "    100000002: \"Active\",\n",
    "    100000003: \"On Hold\",\n",
    "    100000004: \"Completed\",\n",
    "    100000005: \"Canceled\"\n",
    "}\n",
    "\n",
    "print(f\"Pipeline started at {datetime.utcnow().isoformat()}\")\n",
    "print(f\"Accounts: {df_accounts.count()}, Engagements: {df_engagements.count()}\")\n",
    "print(f\"Activities: {df_activities.count()}, Prospects: {df_prospects.count()}\")\n",
    "print(f\"Implementations: {df_implementations.count()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Cell 2: Pipeline Value Analysis \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "# Cast value columns\n",
    "df_eng = (\n",
    "    df_engagements\n",
    "    .withColumn(\"value\", col(\"tvs_value\").cast(DoubleType()))\n",
    "    .withColumn(\"invoiced\", col(\"tvs_invoicedamount\").cast(DoubleType()))\n",
    "    .withColumn(\"status\", col(\"tvs_status\").cast(IntegerType()))\n",
    "    .withColumn(\"eng_type\", col(\"tvs_type\").cast(IntegerType()))\n",
    "    .withColumn(\"start_date\", to_date(col(\"tvs_startdate\")))\n",
    "    .withColumn(\"end_date\", to_date(col(\"tvs_enddate\")))\n",
    ")\n",
    "\n",
    "# Join with accounts for entity info\n",
    "df_eng_with_entity = (\n",
    "    df_eng.alias(\"e\")\n",
    "    .join(\n",
    "        df_accounts.select(\n",
    "            col(\"tvs_consultingaccountid\").alias(\"acct_id\"),\n",
    "            col(\"tvs_entity\").alias(\"entity_code\"),\n",
    "            col(\"tvs_name\").alias(\"account_name\")\n",
    "        ).alias(\"a\"),\n",
    "        col(\"e.tvs_accountid\") == col(\"a.acct_id\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\"entity_name\",\n",
    "        when(col(\"entity_code\") == 100000000, lit(\"Lobbi Consulting\"))\n",
    "        .when(col(\"entity_code\") == 100000001, lit(\"Medicare Consulting\"))\n",
    "        .otherwise(lit(\"Unknown\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Pipeline value by status and entity\n",
    "df_pipeline = (\n",
    "    df_eng_with_entity\n",
    "    .groupBy(\"entity_name\", \"status\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"engagement_count\"),\n",
    "        spark_sum(\"value\").alias(\"total_value\"),\n",
    "        avg(\"value\").alias(\"avg_value\"),\n",
    "        spark_sum(\"invoiced\").alias(\"total_invoiced\")\n",
    "    )\n",
    "    .withColumn(\"status_label\",\n",
    "        when(col(\"status\") == 100000000, lit(\"Proposed\"))\n",
    "        .when(col(\"status\") == 100000001, lit(\"Negotiation\"))\n",
    "        .when(col(\"status\") == 100000002, lit(\"Active\"))\n",
    "        .when(col(\"status\") == 100000003, lit(\"On Hold\"))\n",
    "        .when(col(\"status\") == 100000004, lit(\"Completed\"))\n",
    "        .when(col(\"status\") == 100000005, lit(\"Canceled\"))\n",
    "        .otherwise(lit(\"Unknown\"))\n",
    "    )\n",
    "    .withColumn(\"weighted_pipeline_value\",\n",
    "        when(col(\"status\") == 100000000, col(\"total_value\") * 0.1)\n",
    "        .when(col(\"status\") == 100000001, col(\"total_value\") * 0.4)\n",
    "        .when(col(\"status\") == 100000002, col(\"total_value\") * 0.9)\n",
    "        .when(col(\"status\") == 100000004, col(\"total_value\") * 1.0)\n",
    "        .otherwise(col(\"total_value\") * 0.0)\n",
    "    )\n",
    "    .withColumn(\"calculated_at\", current_timestamp())\n",
    ")\n",
    "\n",
    "df_pipeline.write.format(\"delta\").mode(\"overwrite\").save(f\"{BASE_PATH}/Tables/agg_pipeline\")\n",
    "print(f\"Pipeline analysis written: {df_pipeline.count()} segments\")\n",
    "df_pipeline.select(\"entity_name\", \"status_label\", \"engagement_count\", \"total_value\", \"weighted_pipeline_value\").show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Cell 3: Conversion Rates \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "# SharedProspects conversion analysis\n",
    "df_prospect_analysis = (\n",
    "    df_prospects\n",
    "    .withColumn(\"source_label\",\n",
    "        when(col(\"tvs_sourceentity\") == 100000000, lit(\"TAIA\"))\n",
    "        .when(col(\"tvs_sourceentity\") == 100000001, lit(\"TVS\"))\n",
    "        .when(col(\"tvs_sourceentity\") == 100000002, lit(\"Lobbi Consulting\"))\n",
    "        .when(col(\"tvs_sourceentity\") == 100000003, lit(\"Medicare Consulting\"))\n",
    "        .when(col(\"tvs_sourceentity\") == 100000004, lit(\"Media Company\"))\n",
    "        .otherwise(lit(\"Unknown\"))\n",
    "    )\n",
    "    .withColumn(\"target_label\",\n",
    "        when(col(\"tvs_targetentity\") == 100000000, lit(\"TAIA\"))\n",
    "        .when(col(\"tvs_targetentity\") == 100000001, lit(\"TVS\"))\n",
    "        .when(col(\"tvs_targetentity\") == 100000002, lit(\"Lobbi Consulting\"))\n",
    "        .when(col(\"tvs_targetentity\") == 100000003, lit(\"Medicare Consulting\"))\n",
    "        .when(col(\"tvs_targetentity\") == 100000004, lit(\"Media Company\"))\n",
    "        .otherwise(lit(\"Unknown\"))\n",
    "    )\n",
    "    .withColumn(\"is_converted\", col(\"tvs_status\") == 100000003)\n",
    "    .withColumn(\"referral_date\", to_date(col(\"tvs_referraldate\")))\n",
    "    .withColumn(\"converted_date\", to_date(col(\"tvs_converteddate\")))\n",
    "    .withColumn(\"days_to_convert\",\n",
    "        when(col(\"is_converted\"), datediff(col(\"converted_date\"), col(\"referral_date\")))\n",
    "        .otherwise(lit(None))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Conversion rates by source-target entity pair\n",
    "df_conversion_rates = (\n",
    "    df_prospect_analysis\n",
    "    .groupBy(\"source_label\", \"target_label\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_referrals\"),\n",
    "        count(when(col(\"is_converted\"), True)).alias(\"converted\"),\n",
    "        count(when(col(\"tvs_status\") == 100000004, True)).alias(\"disqualified\"),\n",
    "        count(when(col(\"tvs_status\") == 100000005, True)).alias(\"stale\"),\n",
    "        avg(\"days_to_convert\").alias(\"avg_days_to_convert\")\n",
    "    )\n",
    "    .withColumn(\"conversion_rate\",\n",
    "        spark_round(col(\"converted\") / col(\"total_referrals\") * 100, 2)\n",
    "    )\n",
    "    .withColumn(\"calculated_at\", current_timestamp())\n",
    ")\n",
    "\n",
    "df_conversion_rates.write.format(\"delta\").mode(\"overwrite\").save(f\"{BASE_PATH}/Tables/agg_conversion_rates\")\n",
    "print(f\"Conversion rates written: {df_conversion_rates.count()} entity pairs\")\n",
    "df_conversion_rates.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Cell 4: Engagement Health Scores \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\n",
    "# Score each active engagement based on multiple health indicators\n",
    "\n",
    "df_active_engagements = df_eng_with_entity.filter(col(\"status\").isin([100000002, 100000003]))\n",
    "\n",
    "# Activity recency per engagement\n",
    "df_activity_metrics = (\n",
    "    df_activities\n",
    "    .withColumn(\"completed\", to_date(col(\"tvs_completeddate\")))\n",
    "    .groupBy(col(\"tvs_regardingid\").alias(\"engagement_id\"))\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_activities\"),\n",
    "        count(when(col(\"tvs_status\") == 100000002, True)).alias(\"completed_activities\"),\n",
    "        spark_sum(when(col(\"tvs_type\") == 100000000, lit(1)).otherwise(lit(0))).alias(\"meeting_count\"),\n",
    "        datediff(current_date(), coalesce(spark_round(avg(col(\"completed\").cast(\"long\")), 0).cast(\"date\"), current_date())).alias(\"avg_days_since_activity\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Implementation progress\n",
    "df_impl_metrics = (\n",
    "    df_implementations\n",
    "    .groupBy(col(\"tvs_engagementid\").alias(\"engagement_id\"))\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_phases\"),\n",
    "        count(when(col(\"tvs_status\") == 100000003, True)).alias(\"completed_phases\"),\n",
    "        count(when(col(\"tvs_status\") == 100000002, True)).alias(\"at_risk_phases\"),\n",
    "        avg(coalesce(col(\"tvs_completionpercent\"), lit(0))).alias(\"avg_completion_pct\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate engagement health\n",
    "df_eng_health = (\n",
    "    df_active_engagements\n",
    "    .join(df_activity_metrics, col(\"tvs_engagementid\") == df_activity_metrics[\"engagement_id\"], \"left\")\n",
    "    .join(df_impl_metrics, col(\"tvs_engagementid\") == df_impl_metrics[\"engagement_id\"], \"left\")\n",
    "    .withColumn(\"duration_months\", months_between(current_date(), col(\"start_date\")))\n",
    "    # Score components\n",
    "    .withColumn(\"activity_score\",\n",
    "        when(coalesce(col(\"total_activities\"), lit(0)) >= 5, lit(25))\n",
    "        .when(coalesce(col(\"total_activities\"), lit(0)) >= 2, lit(15))\n",
    "        .otherwise(lit(5))\n",
    "    )\n",
    "    .withColumn(\"progress_score\",\n",
    "        spark_round(coalesce(col(\"avg_completion_pct\"), lit(0)) * 0.35, 2)\n",
    "    )\n",
    "    .withColumn(\"risk_penalty\",\n",
    "        when(coalesce(col(\"at_risk_phases\"), lit(0)) > 2, lit(-20))\n",
    "        .when(coalesce(col(\"at_risk_phases\"), lit(0)) > 0, lit(-10))\n",
    "        .otherwise(lit(0))\n",
    "    )\n",
    "    .withColumn(\"billing_score\",\n",
    "        when(col(\"invoiced\") > col(\"value\") * 0.7, lit(25))\n",
    "        .when(col(\"invoiced\") > col(\"value\") * 0.3, lit(15))\n",
    "        .otherwise(lit(5))\n",
    "    )\n",
    "    .withColumn(\"health_score\",\n",
    "        spark_round(\n",
    "            col(\"activity_score\") + col(\"progress_score\") + col(\"risk_penalty\") + col(\"billing_score\") + lit(15),\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\"health_score\",\n",
    "        when(col(\"health_score\") > 100, lit(100))\n",
    "        .when(col(\"health_score\") < 0, lit(0))\n",
    "        .otherwise(col(\"health_score\"))\n",
    "    )\n",
    "    .withColumn(\"health_label\",\n",
    "        when(col(\"health_score\") >= 75, lit(\"On Track\"))\n",
    "        .when(col(\"health_score\") >= 50, lit(\"Needs Attention\"))\n",
    "        .when(col(\"health_score\") >= 25, lit(\"At Risk\"))\n",
    "        .otherwise(lit(\"Critical\"))\n",
    "    )\n",
    "    .withColumn(\"calculated_at\", current_timestamp())\n",
    "    .select(\n",
    "        \"tvs_engagementid\", \"tvs_name\", \"entity_name\", \"account_name\",\n",
    "        \"value\", \"invoiced\", \"duration_months\",\n",
    "        \"total_activities\", \"completed_activities\", \"total_phases\",\n",
    "        \"completed_phases\", \"at_risk_phases\", \"avg_completion_pct\",\n",
    "        \"health_score\", \"health_label\", \"calculated_at\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df_eng_health.write.format(\"delta\").mode(\"overwrite\").save(f\"{BASE_PATH}/Tables/agg_engagement_health\")\n",
    "print(f\"Engagement health written: {df_eng_health.count()} engagements\")\n",
    "print(\"\\nHealth Distribution:\")\n",
    "df_eng_health.groupBy(\"health_label\").count().show()\n",
    "print(f\"Pipeline completed at {datetime.utcnow().isoformat()}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}