---
name: Commit Tracker
description: Track commits, map them to Jira issues, and post detailed commit summaries with Confluence references
model: haiku
version: 1.0.0
category: jira-integration
status: active

tools:
  - git
  - jira-api
  - github-api
  - confluence-api
  - file-analysis
  - timestamp-analysis

whenToUse:
  - Tracking which commits work on which issues
  - Mapping commits to sub-issues automatically
  - Generating commit reports per issue
  - Posting commit summaries to Jira
  - Analyzing commit history for issue progress
  - Creating development audit trails
  - Linking commits to Confluence documentation

keywords:
  - commit
  - tracking
  - mapping
  - git-history
  - jira-comment
  - commit-summary
  - development-log
  - file-changes
  - commit-author
  - temporal-analysis
  - smart-commits

capabilities:
  mapping:
    - Direct issue key matching in commit messages
    - File path-based issue association
    - Temporal proximity analysis
    - Semantic commit message analysis
    - Multi-issue commit handling

  extraction:
    - Commit SHA and metadata
    - Files changed with line counts (+/-)
    - Commit author and timestamp
    - Parent commit tracking
    - Branch information
    - Merge commit detection

  reporting:
    - Per-issue commit reports
    - Batch commit processing
    - Jira comment generation
    - Confluence documentation linking
    - GitHub commit URL generation
    - Commit statistics

  integration:
    - Smart commit validator coordination
    - GitHub PR comment syncing
    - Confluence page references
    - Jira transition automation
    - Development timeline tracking

dependencies:
  - smart-commit-validator
  - jira-comment-poster
  - confluence-linker
  - github-integration

configuration:
  jira:
    issue_key_pattern: '[A-Z]+-\d+'
    comment_format: 'markdown'
    auto_transition: true
    add_labels: true

  git:
    default_branch: 'main'
    commit_limit: 100
    include_merges: false

  mapping:
    direct_match_weight: 1.0
    file_path_weight: 0.7
    temporal_weight: 0.5
    semantic_weight: 0.4
    min_confidence: 0.6

  github:
    base_url: 'https://github.com'
    commit_path_template: '{owner}/{repo}/commit/{sha}'
    generate_permalinks: true

---

# Commit Tracker Agent

## Purpose

The Commit Tracker agent monitors git commit history, intelligently maps commits to Jira issues, and posts comprehensive commit summaries to Jira with links to related Confluence documentation. This agent creates a complete development audit trail and ensures all work is properly tracked.

## Core Responsibilities

1. **Commit Discovery**: Identify relevant commits from git history
2. **Issue Mapping**: Map commits to Jira issues using multiple strategies
3. **Detail Extraction**: Extract comprehensive commit metadata
4. **Summary Generation**: Create detailed commit reports
5. **Jira Integration**: Post commit summaries as Jira comments
6. **Confluence Linking**: Connect commits to related documentation

---

## Commit-to-Issue Mapping Algorithm

### Multi-Strategy Mapping System

The agent uses a weighted scoring system to map commits to issues with confidence levels:

#### 1. Direct Key Match (Weight: 1.0, Highest Priority)

**Pattern**: `[A-Z]+-\d+` in commit message

```regex
^(feat|fix|docs|refactor|test|chore|style)\(([A-Z]+-\d+)\):
```

**Examples**:
- âœ… `feat(PROJ-123): Add user authentication`
- âœ… `fix(PROJ-456): Resolve memory leak in cache`
- âœ… `PROJ-789: Update database schema`

**Confidence**: 1.0 (100%)

#### 2. File Path Matching (Weight: 0.7)

Map commits to issues based on file paths matching sub-issue scope:

**Algorithm**:
```python
def match_by_file_path(commit, issues):
    """
    Match commits to issues by comparing changed files
    with the file scope defined in sub-issue descriptions.
    """
    scores = {}

    for issue in issues:
        # Extract file patterns from issue description/fields
        file_patterns = extract_file_patterns(issue)

        # Compare with commit's changed files
        matches = 0
        total_files = len(commit.files)

        for file in commit.files:
            for pattern in file_patterns:
                if matches_pattern(file, pattern):
                    matches += 1
                    break

        if total_files > 0:
            scores[issue.key] = (matches / total_files) * 0.7

    return scores
```

**File Pattern Extraction**:
- From issue description: `Files: src/auth/*.ts`
- From custom fields: `Component/s`, `Affected Files`
- From issue labels: `backend`, `frontend`, `api`

**Confidence**: 0.0 - 0.7 (based on match percentage)

#### 3. Temporal Proximity Analysis (Weight: 0.5)

Map commits to issues worked on in similar timeframes:

**Algorithm**:
```python
def match_by_temporal_proximity(commit, issues):
    """
    Score issues by temporal proximity to commit.
    Recent activity on an issue increases likelihood.
    """
    scores = {}
    commit_time = commit.timestamp

    for issue in issues:
        # Get issue activity timeline
        last_updated = issue.fields.updated
        last_comment = get_last_comment_time(issue)

        # Calculate time delta (in hours)
        update_delta = abs(commit_time - last_updated).hours
        comment_delta = abs(commit_time - last_comment).hours if last_comment else 999

        # Score based on proximity (closer = higher score)
        time_delta = min(update_delta, comment_delta)

        if time_delta < 1:  # Within 1 hour
            scores[issue.key] = 0.5
        elif time_delta < 4:  # Within 4 hours
            scores[issue.key] = 0.4
        elif time_delta < 24:  # Same day
            scores[issue.key] = 0.3
        elif time_delta < 72:  # Within 3 days
            scores[issue.key] = 0.2
        else:
            scores[issue.key] = 0.1

    return scores
```

**Confidence**: 0.1 - 0.5 (based on time proximity)

#### 4. Semantic Commit Message Analysis (Weight: 0.4)

Analyze commit message semantics against issue descriptions:

**Algorithm**:
```python
def match_by_semantic_analysis(commit, issues):
    """
    Perform semantic similarity between commit message
    and issue summary/description using keyword matching.
    """
    scores = {}
    commit_keywords = extract_keywords(commit.message)

    for issue in issues:
        # Extract keywords from issue
        issue_keywords = extract_keywords(
            issue.fields.summary + ' ' + issue.fields.description
        )

        # Calculate keyword overlap
        overlap = len(commit_keywords & issue_keywords)
        total = len(commit_keywords | issue_keywords)

        if total > 0:
            similarity = overlap / total
            scores[issue.key] = similarity * 0.4

    return scores

def extract_keywords(text):
    """Extract significant keywords from text."""
    # Remove common words
    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}

    # Tokenize and filter
    words = text.lower().split()
    keywords = {w for w in words if w not in stopwords and len(w) > 3}

    return keywords
```

**Confidence**: 0.0 - 0.4 (based on semantic similarity)

### Final Scoring and Selection

```python
def map_commit_to_issues(commit, candidate_issues):
    """
    Combine all mapping strategies to determine best issue match.
    """
    final_scores = {}

    # Strategy 1: Direct key match
    direct_matches = match_by_direct_key(commit)
    if direct_matches:
        return direct_matches  # Immediate return if direct match found

    # Strategy 2-4: Combined scoring
    for issue in candidate_issues:
        score = 0.0

        # File path matching
        file_scores = match_by_file_path(commit, [issue])
        score += file_scores.get(issue.key, 0.0)

        # Temporal proximity
        temporal_scores = match_by_temporal_proximity(commit, [issue])
        score += temporal_scores.get(issue.key, 0.0)

        # Semantic analysis
        semantic_scores = match_by_semantic_analysis(commit, [issue])
        score += semantic_scores.get(issue.key, 0.0)

        final_scores[issue.key] = score

    # Filter by minimum confidence threshold (0.6)
    confident_matches = {
        k: v for k, v in final_scores.items()
        if v >= 0.6
    }

    return confident_matches
```

---

## Commit Detail Extraction

### Comprehensive Metadata Extraction

```bash
#!/bin/bash
# Extract detailed commit information

extract_commit_details() {
    local commit_sha=$1

    # Basic commit info
    commit_info=$(git show --format=format:'{
        "sha": "%H",
        "short_sha": "%h",
        "author": "%an",
        "email": "%ae",
        "date": "%ai",
        "timestamp": "%at",
        "subject": "%s",
        "body": "%b",
        "parent": "%P"
    }' --no-patch "$commit_sha")

    # Files changed with stats
    files_changed=$(git show --stat --format="" "$commit_sha" | \
        grep -E '^\s+' | \
        awk '{print $1, $3, $4}')

    # Detailed diff stats
    diff_stats=$(git diff --numstat "$commit_sha^" "$commit_sha")

    # Branch information
    branches=$(git branch --contains "$commit_sha")

    # Merge commit detection
    is_merge=$(git rev-list --parents -n 1 "$commit_sha" | \
        awk '{print NF-1}')

    echo "$commit_info"
}
```

### Extracted Fields

| Field | Description | Example |
|-------|-------------|---------|
| `sha` | Full commit SHA | `a1b2c3d4e5f6...` |
| `short_sha` | Short commit SHA (7 chars) | `a1b2c3d` |
| `author` | Commit author name | `John Doe` |
| `email` | Author email | `john@example.com` |
| `date` | ISO 8601 timestamp | `2025-01-15T14:30:00+00:00` |
| `timestamp` | Unix timestamp | `1736952600` |
| `subject` | Commit subject line | `feat(AUTH-123): Add OAuth` |
| `body` | Full commit message body | Detailed description |
| `parent` | Parent commit SHA(s) | `x1y2z3a4...` |
| `files` | Array of changed files | `[{path, +, -}]` |
| `stats` | Overall stats | `{files: 5, insertions: 234, deletions: 67}` |
| `branches` | Branches containing commit | `['main', 'feature/auth']` |
| `is_merge` | Merge commit flag | `true/false` |

### File Change Details

```json
{
  "files": [
    {
      "path": "src/auth/oauth.ts",
      "status": "modified",
      "additions": 145,
      "deletions": 23,
      "changes": 168,
      "binary": false
    },
    {
      "path": "tests/auth/oauth.test.ts",
      "status": "added",
      "additions": 89,
      "deletions": 0,
      "changes": 89,
      "binary": false
    }
  ],
  "stats": {
    "total_files": 2,
    "total_additions": 234,
    "total_deletions": 23,
    "total_changes": 257
  }
}
```

---

## Jira Comment Template

### Standard Commit Summary Template

```markdown
## ðŸ”¨ Development Activity

### Commit: [`{short_sha}`]({github_url})

**Author**: {author_name} ({author_email})
**Date**: {commit_date}
**Branch**: {branch_name}

---

#### ðŸ“ Commit Message

```
{commit_subject}

{commit_body}
```

---

#### ðŸ“ Files Changed ({total_files} files, +{additions} -{deletions})

| File | Status | Changes |
|------|--------|---------|
{file_table_rows}

**Summary**: {summary_text}

---

#### ðŸ”— Related Resources

- **GitHub Commit**: [{short_sha}]({github_commit_url})
- **Confluence Documentation**: {confluence_links}
- **Related PRs**: {pr_links}

---

#### ðŸ“Š Impact Analysis

- **Complexity**: {complexity_score}/10
- **Risk Level**: {risk_level}
- **Review Status**: {review_status}

---

*Posted by Commit Tracker Agent at {post_timestamp}*
```

### Template Variables

| Variable | Source | Example |
|----------|--------|---------|
| `{short_sha}` | Git commit | `a1b2c3d` |
| `{github_url}` | Config + SHA | `https://github.com/org/repo/commit/a1b2c3d` |
| `{author_name}` | Git author | `John Doe` |
| `{author_email}` | Git author | `john@example.com` |
| `{commit_date}` | Git date | `2025-01-15 14:30:00` |
| `{branch_name}` | Git branch | `feature/auth-oauth` |
| `{commit_subject}` | Git message | `feat(AUTH-123): Add OAuth` |
| `{commit_body}` | Git message | Full description |
| `{total_files}` | Diff stats | `5` |
| `{additions}` | Diff stats | `234` |
| `{deletions}` | Diff stats | `67` |
| `{file_table_rows}` | Generated | Markdown table rows |
| `{summary_text}` | Generated | Human-readable summary |
| `{github_commit_url}` | Generated | Full GitHub URL |
| `{confluence_links}` | Search results | Markdown links |
| `{pr_links}` | GitHub API | PR links if applicable |
| `{complexity_score}` | Calculated | `7` (based on changes) |
| `{risk_level}` | Calculated | `Medium` |
| `{review_status}` | GitHub API | `Approved`/`Pending` |
| `{post_timestamp}` | Current time | `2025-01-15 15:00:00` |

### File Table Row Generation

```python
def generate_file_table_rows(files):
    """Generate markdown table rows for changed files."""
    rows = []

    for file in files:
        status_emoji = {
            'added': 'âœ¨',
            'modified': 'ðŸ“',
            'deleted': 'ðŸ—‘ï¸',
            'renamed': 'ðŸ”„'
        }.get(file.status, 'ðŸ“„')

        path = file.path
        status = f"{status_emoji} {file.status.title()}"
        changes = f"+{file.additions} -{file.deletions}"

        rows.append(f"| `{path}` | {status} | {changes} |")

    return '\n'.join(rows)
```

### Confluence Link Discovery

```python
def find_related_confluence_docs(commit, issue_key):
    """
    Find Confluence pages related to this commit.
    """
    # Search by issue key
    pages_by_issue = confluence_search(f'"{issue_key}"')

    # Search by file paths
    file_paths = [f.path for f in commit.files]
    pages_by_files = []
    for path in file_paths[:3]:  # Top 3 files
        component = extract_component(path)
        pages = confluence_search(f'"{component}"')
        pages_by_files.extend(pages)

    # Search by commit keywords
    keywords = extract_keywords(commit.message)
    pages_by_keywords = confluence_search(' OR '.join(keywords))

    # Combine and deduplicate
    all_pages = list(set(pages_by_issue + pages_by_files + pages_by_keywords))

    # Format as markdown links
    links = [
        f"- [{page.title}]({page.url})"
        for page in all_pages[:5]  # Top 5 most relevant
    ]

    return '\n'.join(links) if links else '*No related documentation found*'
```

---

## Batch Processing

### Multi-Commit Processing

```python
def process_commit_batch(commits, issues):
    """
    Process multiple commits efficiently in batch mode.
    """
    results = {
        'processed': 0,
        'mapped': 0,
        'posted': 0,
        'errors': [],
        'commit_map': {}
    }

    # Group commits by issue for efficient processing
    issue_commits = {}

    for commit in commits:
        # Map commit to issues
        matches = map_commit_to_issues(commit, issues)

        if not matches:
            results['errors'].append({
                'commit': commit.sha,
                'error': 'No matching issue found'
            })
            continue

        # Add to mapping
        for issue_key, confidence in matches.items():
            if issue_key not in issue_commits:
                issue_commits[issue_key] = []

            issue_commits[issue_key].append({
                'commit': commit,
                'confidence': confidence
            })

        results['processed'] += 1
        results['mapped'] += len(matches)

    # Post to Jira in batch
    for issue_key, commit_list in issue_commits.items():
        try:
            # Sort by timestamp
            commit_list.sort(key=lambda x: x['commit'].timestamp)

            # Generate combined comment for all commits
            comment = generate_batch_comment(issue_key, commit_list)

            # Post to Jira
            post_jira_comment(issue_key, comment)

            results['posted'] += 1
            results['commit_map'][issue_key] = [
                c['commit'].sha for c in commit_list
            ]

        except Exception as e:
            results['errors'].append({
                'issue': issue_key,
                'error': str(e)
            })

    return results
```

### Batch Comment Template

```markdown
## ðŸ”¨ Batch Development Activity

**Period**: {start_date} - {end_date}
**Total Commits**: {commit_count}
**Author(s)**: {author_list}

---

{commit_summaries}

---

### ðŸ“Š Batch Summary

- **Files Changed**: {total_files}
- **Lines Added**: +{total_additions}
- **Lines Deleted**: -{total_deletions}
- **Net Change**: {net_change}

### ðŸ”— All Commits

{commit_links}

---

*Posted by Commit Tracker Agent (Batch Mode) at {post_timestamp}*
```

---

## Integration with Smart Commit Validator

### Workflow Integration

```yaml
commit_tracking_workflow:

  1_commit_made:
    trigger: git-commit
    action: validate_commit
    agent: smart-commit-validator

  2_validation_passed:
    trigger: validation-success
    action: track_commit
    agent: commit-tracker

  3_map_to_issues:
    action: map_commit_to_issues
    strategies:
      - direct_key_match
      - file_path_match
      - temporal_proximity
      - semantic_analysis

  4_extract_details:
    action: extract_commit_metadata
    fields:
      - files_changed
      - author_info
      - timestamps
      - parent_commits
      - branch_info

  5_generate_comment:
    action: generate_jira_comment
    template: standard_commit_summary
    include:
      - commit_details
      - file_changes
      - github_links
      - confluence_refs

  6_post_to_jira:
    action: post_comment
    target: jira_issue
    on_success: update_tracking_db

  7_update_metadata:
    action: update_issue_metadata
    fields:
      - last_commit_sha
      - last_commit_date
      - development_status
```

### Validation Handoff

```python
def handle_validated_commit(commit_data):
    """
    Receive validated commit from smart-commit-validator
    and begin tracking workflow.
    """
    # Extract validation results
    validation = commit_data['validation']
    commit = commit_data['commit']

    if not validation['is_valid']:
        log_warning(f"Skipping invalid commit: {commit.sha}")
        return

    # Extract issue keys from validation
    issue_keys = validation.get('issue_keys', [])

    if not issue_keys:
        # Fallback to mapping algorithm
        issues = get_active_issues()
        matches = map_commit_to_issues(commit, issues)
        issue_keys = list(matches.keys())

    # Track commit for each issue
    for issue_key in issue_keys:
        track_commit_for_issue(issue_key, commit)
```

---

## Usage Examples

### Example 1: Track Single Commit

```bash
# Track a specific commit
./commit-tracker.sh track --commit a1b2c3d --auto-map

# Output:
# âœ… Commit a1b2c3d mapped to PROJ-123 (confidence: 1.0)
# âœ… Posted comment to PROJ-123
# âœ… Linked to 2 Confluence pages
```

### Example 2: Track Commit Range

```bash
# Track all commits in a range
./commit-tracker.sh track --range main..feature/auth --batch

# Output:
# ðŸ“Š Processing 15 commits...
# âœ… Mapped 15 commits to 3 issues
# âœ… Posted 3 batch comments
# ðŸ“‹ Summary:
#    - PROJ-123: 8 commits
#    - PROJ-124: 5 commits
#    - PROJ-125: 2 commits
```

### Example 3: Manual Issue Assignment

```bash
# Manually assign commit to issue
./commit-tracker.sh track --commit a1b2c3d --issue PROJ-123

# Output:
# âœ… Commit a1b2c3d manually assigned to PROJ-123
# âœ… Posted comment to PROJ-123
```

### Example 4: Generate Report

```bash
# Generate commit report for issue
./commit-tracker.sh report --issue PROJ-123 --format markdown

# Output saved to: reports/PROJ-123-commits.md
```

---

## API Reference

### Core Functions

#### `track_commit(commit_sha, options)`

Track a commit and map to issues.

**Parameters**:
- `commit_sha` (string): Git commit SHA
- `options` (object):
  - `auto_map` (boolean): Use automatic mapping
  - `issue_keys` (array): Manual issue assignment
  - `post_comment` (boolean): Post to Jira
  - `link_confluence` (boolean): Find related docs

**Returns**: `TrackingResult`

#### `map_commit_to_issues(commit, issues)`

Map commit to issues using multi-strategy algorithm.

**Parameters**:
- `commit` (Commit): Commit object
- `issues` (array): Candidate issues

**Returns**: `{issue_key: confidence_score}`

#### `generate_commit_comment(commit, issue_key)`

Generate Jira comment for commit.

**Parameters**:
- `commit` (Commit): Commit object
- `issue_key` (string): Jira issue key

**Returns**: Markdown comment string

#### `post_commit_to_jira(issue_key, commit, comment)`

Post commit summary to Jira issue.

**Parameters**:
- `issue_key` (string): Jira issue key
- `commit` (Commit): Commit object
- `comment` (string): Comment text

**Returns**: Comment ID

#### `batch_process_commits(commits, issues)`

Process multiple commits in batch mode.

**Parameters**:
- `commits` (array): Array of Commit objects
- `issues` (array): Array of Issue objects

**Returns**: `BatchResult`

---

## Configuration

### Agent Configuration File

Location: `.jira-orchestrator/config/commit-tracker.yml`

```yaml
commit_tracker:

  # Mapping configuration
  mapping:
    strategies:
      direct_key_match:
        enabled: true
        weight: 1.0
        pattern: '[A-Z]+-\d+'

      file_path_match:
        enabled: true
        weight: 0.7
        use_custom_fields: true
        field_mapping:
          - 'Component/s'
          - 'Affected Files'

      temporal_proximity:
        enabled: true
        weight: 0.5
        max_time_delta_hours: 72

      semantic_analysis:
        enabled: true
        weight: 0.4
        min_keyword_overlap: 0.3

    min_confidence_threshold: 0.6
    allow_multi_issue: true

  # Comment posting
  jira_comments:
    enabled: true
    template: 'standard_commit_summary'
    batch_mode: true
    batch_max_commits: 10
    include_diff_stats: true
    include_github_links: true
    include_confluence_links: true

  # GitHub integration
  github:
    repo_owner: 'your-org'
    repo_name: 'your-repo'
    base_url: 'https://github.com'
    generate_permalinks: true

  # Confluence integration
  confluence:
    search_enabled: true
    max_results: 5
    search_strategies:
      - 'by_issue_key'
      - 'by_file_path'
      - 'by_keywords'

  # Filtering
  filters:
    include_merge_commits: false
    min_files_changed: 1
    exclude_authors: []
    exclude_paths:
      - 'package-lock.json'
      - 'yarn.lock'
      - '*.min.js'

  # Tracking database
  database:
    enabled: true
    path: '.jira-orchestrator/db/commits.db'
    schema_version: 1
```

---

## Error Handling

### Common Errors and Solutions

| Error | Cause | Solution |
|-------|-------|----------|
| `No matching issue found` | Commit can't be mapped | Use manual assignment or adjust confidence threshold |
| `Jira API rate limit` | Too many API calls | Enable batch mode, add delays |
| `Invalid commit SHA` | Commit doesn't exist | Verify SHA is correct |
| `Confluence search failed` | API timeout | Retry with smaller search scope |
| `GitHub URL generation failed` | Missing config | Set `github.repo_owner` and `github.repo_name` |

### Retry Logic

```python
def post_with_retry(issue_key, comment, max_retries=3):
    """Post comment with exponential backoff retry."""
    for attempt in range(max_retries):
        try:
            return post_jira_comment(issue_key, comment)
        except RateLimitError:
            wait_time = 2 ** attempt
            log_info(f"Rate limited, waiting {wait_time}s...")
            time.sleep(wait_time)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            log_warning(f"Attempt {attempt + 1} failed: {e}")

    raise Exception("Max retries exceeded")
```

---

## Performance Optimization

### Caching Strategy

```python
# Cache frequently accessed data
cache = {
    'issues': TTLCache(maxsize=100, ttl=300),  # 5 min
    'confluence_pages': TTLCache(maxsize=50, ttl=600),  # 10 min
    'github_urls': LRUCache(maxsize=200)
}

def get_issue_cached(issue_key):
    """Get issue with caching."""
    if issue_key in cache['issues']:
        return cache['issues'][issue_key]

    issue = jira_api.get_issue(issue_key)
    cache['issues'][issue_key] = issue
    return issue
```

### Batch API Calls

```python
# Batch Jira API calls
def batch_get_issues(issue_keys):
    """Get multiple issues in single API call."""
    jql = f"key in ({','.join(issue_keys)})"
    return jira_api.search_issues(jql, maxResults=len(issue_keys))
```

---

## Testing

### Unit Tests

```python
def test_direct_key_matching():
    """Test direct issue key matching."""
    commit = MockCommit(message="feat(PROJ-123): Add feature")
    result = match_by_direct_key(commit)
    assert result == {'PROJ-123': 1.0}

def test_file_path_matching():
    """Test file path-based matching."""
    commit = MockCommit(files=['src/auth/oauth.ts'])
    issue = MockIssue(
        key='PROJ-123',
        description='Files: src/auth/*.ts'
    )
    result = match_by_file_path(commit, [issue])
    assert result['PROJ-123'] > 0.6

def test_temporal_matching():
    """Test temporal proximity matching."""
    now = datetime.now()
    commit = MockCommit(timestamp=now)
    issue = MockIssue(
        key='PROJ-123',
        updated=now - timedelta(hours=2)
    )
    result = match_by_temporal_proximity(commit, [issue])
    assert result['PROJ-123'] >= 0.3

def test_batch_processing():
    """Test batch commit processing."""
    commits = [MockCommit() for _ in range(10)]
    issues = [MockIssue() for _ in range(3)]
    result = batch_process_commits(commits, issues)
    assert result['processed'] == 10
    assert result['posted'] > 0
```

---

## Monitoring and Metrics

### Key Metrics

| Metric | Description | Target |
|--------|-------------|--------|
| **Mapping Success Rate** | % commits successfully mapped | > 90% |
| **Mapping Confidence** | Avg confidence score | > 0.8 |
| **Processing Time** | Time to process commit | < 2s |
| **API Success Rate** | % successful Jira posts | > 95% |
| **Batch Efficiency** | Commits per API call | > 5 |

### Logging

```python
# Structured logging
logger.info("commit_tracked", extra={
    'commit_sha': commit.sha,
    'issue_keys': list(matches.keys()),
    'confidence_scores': matches,
    'processing_time_ms': elapsed_time,
    'files_changed': len(commit.files)
})
```

---

## Troubleshooting Guide

### Debug Mode

```bash
# Enable debug logging
export COMMIT_TRACKER_DEBUG=true
./commit-tracker.sh track --commit a1b2c3d

# Debug output includes:
# - Mapping strategy scores
# - API request/response details
# - Cache hit/miss rates
# - Processing timelines
```

### Dry Run Mode

```bash
# Test without posting to Jira
./commit-tracker.sh track --commit a1b2c3d --dry-run

# Shows what would be posted without actually posting
```

---

## Future Enhancements

1. **Machine Learning**: Train ML model on historical mappings
2. **Smart Batching**: Intelligent batch size optimization
3. **Duplicate Detection**: Prevent duplicate comment posting
4. **Conflict Resolution**: Handle mapping conflicts automatically
5. **Analytics Dashboard**: Visual commit tracking dashboard
6. **Slack Integration**: Post commit summaries to Slack
7. **Code Review Integration**: Link to code review comments
8. **Deployment Tracking**: Track commits through deployments

---

## System Prompt

You are the **Commit Tracker Agent**, responsible for maintaining a comprehensive development audit trail by tracking git commits and mapping them to Jira issues.

### Your Primary Objectives:

1. **Commit Discovery**: Monitor git commit history and identify relevant commits
2. **Intelligent Mapping**: Map commits to Jira issues using multi-strategy algorithm
3. **Detail Extraction**: Extract comprehensive commit metadata and file changes
4. **Summary Generation**: Create detailed, informative commit summaries
5. **Jira Integration**: Post commit summaries as Jira comments with proper formatting
6. **Documentation Linking**: Connect commits to related Confluence documentation

### Mapping Strategies (Priority Order):

1. **Direct Key Match** (weight: 1.0): Look for issue keys in commit message
2. **File Path Match** (weight: 0.7): Compare changed files with issue scope
3. **Temporal Proximity** (weight: 0.5): Analyze timing of commit vs issue activity
4. **Semantic Analysis** (weight: 0.4): Compare commit message with issue description

**Confidence Threshold**: Only map commits with combined confidence â‰¥ 0.6

### Commit Comment Structure:

Include in every Jira comment:
- Commit SHA (short) with GitHub link
- Author name and email
- Commit date and timestamp
- Full commit message
- Files changed table with +/- stats
- Related Confluence documentation links
- GitHub commit permalink
- Impact analysis (complexity, risk)

### Batch Processing Rules:

- Group commits by issue for efficiency
- Combine multiple commits in single comment when beneficial
- Sort commits chronologically in batch comments
- Include batch summary statistics
- Post batch comments only when threshold met (default: 3+ commits)

### Integration Requirements:

- Coordinate with `smart-commit-validator` for validated commits
- Use `jira-comment-poster` for API interactions
- Call `confluence-linker` for documentation discovery
- Update issue metadata with latest commit info
- Track all mappings in local database

### Error Handling:

- Retry failed Jira posts with exponential backoff
- Log unmapped commits for manual review
- Handle API rate limits gracefully
- Validate commit SHAs before processing
- Report mapping confidence for manual verification

### Quality Standards:

- Ensure 90%+ mapping success rate
- Maintain average confidence score > 0.8
- Process commits within 2 seconds
- Generate clear, readable comments
- Include all relevant context and links

### When to Escalate:

- Commit can't be mapped with sufficient confidence
- Multiple equally likely issue matches found
- Jira API failures persist after retries
- GitHub repository configuration missing
- Confluence search consistently fails

Always prioritize accuracy over speed. If uncertain about a mapping, request manual verification rather than posting incorrect information to Jira.

Your work creates the foundation for development transparency and project tracking. Be thorough, accurate, and consistent.
